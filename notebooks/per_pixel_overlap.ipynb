{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22664,
     "status": "ok",
     "timestamp": 1575853439678,
     "user": {
      "displayName": "cvfinal project",
      "photoUrl": "",
      "userId": "01606994284983043688"
     },
     "user_tz": 300
    },
    "id": "q6ZyblpkLEIo",
    "outputId": "fe8e50cc-2326-4ce0-f8df-7e43e12c1dd7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d7ce2fce669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "import random\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9FyP2OPLLPJK"
   },
   "outputs": [],
   "source": [
    "def calculate_per_pixel_change(img1, img2):\n",
    "    #epsilon = 1e-5\n",
    "    #img1_normalized = (img1 - img1.mean(axis=0)) / (img1.std(axis=0) + epsilon)\n",
    "    #img2_normalized = (img2 - img2.mean(axis=0)) / (img2.std(axis=0) + epsilon)\n",
    "    #img_diff = img1_normalized - img2_normalized\n",
    "    img_diff = img1 - img2\n",
    "    img_diff[img_diff<0] = 0\n",
    "    manhattan_norm = np.sum(abs(img_diff))\n",
    "    zero_norm = np.linalg.norm(img_diff.ravel(), 0)\n",
    "    return manhattan_norm, zero_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0t5Sx0ywRq0w"
   },
   "outputs": [],
   "source": [
    "def run_sift(color1,color2,dir1=None,dir=None,fname1=None,fname2=None):\n",
    "    img1 = cv2.cvtColor(color1, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(color2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sift = cv2.xfeatures2d.SURF_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "    output1 = cv2.drawKeypoints(color1,kp1,None,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    output2 = cv2.drawKeypoints(color2,kp2,None,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    bf = cv2.BFMatcher(normType=cv2.NORM_L2)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    sortedgood = sorted(good, key = lambda x:x.distance)\n",
    "    draw = sortedgood[:20]\n",
    "    output3 = cv2.drawMatches(color1,kp1,color2,kp2,draw,None,flags=2)\n",
    "    #cv2.imwrite(os.path.join(dir2, fname2) + '_matches.tif', output3)\n",
    "\n",
    "    if len(good) >= 4:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    else:\n",
    "        print('NOT ENOUGH MATCHES FOR HOMOGRAPHY')\n",
    "        return\n",
    "\n",
    "    H = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)[0]\n",
    "    # dst = cv2.warpPerspective(color2, H, (img1.shape[1] + img2.shape[1], img1.shape[0]))\n",
    "    # dst[0:img1.shape[0], 0:img1.shape[1]] = color1\n",
    "    # cv2.imwrite(os.path.join(dir2, fname2) + '_stitched.tif', dst)\n",
    "    #dst = cv2.warpPerspective(color2, H, img2.shape)\n",
    "    #cv2.imwrite(os.path.join(dir2, fname2) + '_homography.tif', dst)\n",
    "    return H \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUzKPFL2GyE8"
   },
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5073,
     "status": "ok",
     "timestamp": 1575869724327,
     "user": {
      "displayName": "cvfinal project",
      "photoUrl": "",
      "userId": "01606994284983043688"
     },
     "user_tz": 300
    },
    "id": "DlAdGwxMLeBH",
    "outputId": "f9727c54-c52e-4623-da5b-072d7b8d1376"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5f6b06004dce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#mask_dir = '../predictions_fpn/'\n",
    "mask_dir = '../predictions_unet/'\n",
    "pre_dir = '../data/pre_event'\n",
    "post_dir = '../data/post_event'\n",
    "homographies = '../homographies.txt'\n",
    "homo = {}\n",
    "import re\n",
    "\n",
    "with open(homographies) as fin:\n",
    "  fname = None\n",
    "  row = 0 \n",
    "  mat =  np.zeros((3, 3))\n",
    "  for line in fin:\n",
    "    if line != '\\n':\n",
    "      if 'tif' in line: \n",
    "        fname = line.replace('\\n', '')\n",
    "        row = 0\n",
    "      else: \n",
    "        #print(\"line: \", line)\n",
    "        line = line.replace('[','')\n",
    "        line = line.replace(']', '')\n",
    "        line = line.replace(', ', '')\n",
    "        #print(\"post stripping line: \", line)\n",
    "        #print([float(num) for num in line.split(' ') if num!=''])\n",
    "        mat[row] = np.asarray([float(num) for num in line.split(' ') if num!=''])\n",
    "        row = row + 1\n",
    "        if row == 3: \n",
    "          homo[fname] = mat\n",
    "          mat =  np.zeros((3, 3))  \n",
    "          row = 0\n",
    "          fname = None\n",
    "#print(homo)\n",
    "files = os.listdir(mask_dir)\n",
    "for f in files: \n",
    "  if 'pre' in f:\n",
    "    pre = f\n",
    "    post = pre.replace('pre', 'post')\n",
    "\n",
    "    source = pre.replace('jpg', 'tif')\n",
    "    source = source.replace('_pre', '')\n",
    "    #print(source)\n",
    "\n",
    "    pre_source = cv2.imread(os.path.join(pre_dir, source), cv2.IMREAD_COLOR)\n",
    "    post_source = cv2.imread(os.path.join(post_dir, source), cv2.IMREAD_COLOR)\n",
    "\n",
    "    #homo = run_sift(pre_source, post_source)\n",
    "    h = np.array([])\n",
    "    #print(h.size)\n",
    "    if source in homo:\n",
    "      h = homo[source]\n",
    "      #print(h)\n",
    "    pre_mask = cv2.imread(os.path.join(mask_dir, pre), cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "    if h.size != 0: \n",
    "      pre_mask = cv2.warpPerspective(pre_mask, h, pre_mask.shape)\n",
    "\n",
    "    post_mask = cv2.imread(os.path.join(mask_dir, post), cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "    pre_mask[pre_mask>0.5] = 1\n",
    "    pre_mask[pre_mask<0.5] = 0\n",
    "\n",
    "    post_mask[post_mask>0.5] = 1\n",
    "    post_mask[post_mask<0.5] = 0\n",
    "    manhattan_norm, zero_norm = calculate_per_pixel_change(pre_mask, post_mask)\n",
    "    #print(pre, source, 1-manhattan_norm/np.sum(pre_mask), 1-zero_norm/np.sum(pre_mask))\n",
    "    access_index1 = 1-manhattan_norm/np.sum(pre_mask)\n",
    "    access_index2 = 1-zero_norm/np.sum(pre_mask)\n",
    "    img_diff = pre_mask - post_mask\n",
    "    img_diff[img_diff<0] = 0\n",
    "    if(access_index1 > 0.1 or access_index2 > 0.1):\n",
    "      print(source, access_index1, access_index2)\n",
    "      visualize(\n",
    "          pre_event_mask = pre_mask, \n",
    "          post_event_mask = post_mask, \n",
    "          event_mask_differences=img_diff\n",
    "      )\n",
    "    #print(\"Manhattan norm: {} per pizel: {}\".format(manhattan_norm, manhattan_norm / cv2.GetSize(gray1)))\n",
    "    #print(\"Zero norm: {} per pizel: {}\".format(zero_norm, zero_norm / cv2.GetSize(gray1)))\n",
    "\n",
    "#img1 = cv2.imread(os.path.join(args.directory, args.img1), cv2.IMREAD_COLOR)\n",
    "#img2 = cv2.imread(os.path.join(args.directory, args.img2), cv2.IMREAD_COLOR)\n",
    "#gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) / 255.0\n",
    "#gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) / 255.0\n",
    "#manhattan_norm, zero_norm = calculate_per_pixel_change(gray1, gray2)\n",
    "#print(\"Manhattan norm: {} per pizel: {}\".format(manhattan_norm, manhattan_norm / cv.GetSize(gray1)))\n",
    "#print(\"Zero norm: {} per pizel: {}\".format(zero_norm, zero_norm / cv.GetSize(gray1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQ3_mfCQgxt7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "per_pixel_overlap.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
