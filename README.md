# CS461 Final Project:

## Repository Organization
    cs461-final-project/
      |- README.md
      |- post_event_selection.py --> 
      |- retrieve_ground_truth.py --> 
      |- scrape_digitalglobe.py --> 
      |- split_data.py --> 
      |- calculate_per_pixel_change.py --> 
      |- data_preprocessing.py --> Apply density filter and image augmentation to training dataset
      |- image_matching.py --> Perform SURF feature matching and perspective transformation for pre and post image matching
      |- prepare_satellite_imgs.py --> 
      |- unet.py --> 
      |- notebooks/
         |- UNet.ipynb
         |- damage_ground_truth.ipynb
      |- data/
         |- ground_truth
         	|- ...
         |- post_event
         	|- ...
         |- pre_event
         	|- ...
         |- roads
         	|- train
         	|- output
         	|- ...
## Data Preprocessing
The directory containing the data to process is used as an argument when calling the program. Here is an example command to apply preprocessing to the `train` images in the `roads` directory.

```python data_preprocessing.py data/roads/train/```

## Image Matching
`run_DP.py` is used to compute the true edit distance. The script calls `edit_distance_DP.py`.  
- For the synthetic data, all the sequences were generated as separate .txt files. The input sequence files are in `/data/synth_*.txt`(10 pairs) and `/synth_data/synth_*.txt`(1 test and 5 edited sequences each, yields a total of 50 pairs).
- For the genomic data, all the sequences are in `/data/ecoli_realdata.txt`. The first 600 sequences were used.
- Note that this code takes a long time to run! We ran our code for 12 hours.

## Tuning Parameters
`tune_parameters.py` is used to iterate through multiple combinations of k (k-mer length) and L (size of fingerpring).  
- `main` is used to run the functions `tune` and `get_jaccard`. This will calculate the true Jaccard simlarity and the estimates of the four different MinHash implementations for all the combinations of k and L.  
- `main_summary` is used to run `summary` for each k, L pair and uses the files generated by `main` to compute summary metrics. It returns the average error of the Jaccard similarity estimate for the MinHash algorithms, and returns a list of the true edit distance (this file already exists and must be passed in as an input) and the true Jaccard similarity. 

## Estimating Edit Distance
The `run_experiment.py` is used to compute the estimated edit distance using the computed Jaccard simlilarities. The output file will have the following:
- Length of the 2 sequences (len_x, len_y)
- True Jaccard and estimated Jaccard from the 4 algorithms: TJ, J1, J2, J3, J4
- True edit distance computed from Needleman-Wunsch: trueED
- 3 Estimated edit distances for each of the Jaccard simlarity values (lower, upper bound from IEEE paper, our point estimate): TED (from TJ), ED1, ED2, ED3, ED4 (from J1, J2, J3, J4 respectively).

## Benchmarking
The `profiler.py` is used to benchmark time on the four MinHash implementations. This profiling is done using a common set of parameters: 16 k-mer length, 128 hash functions, stride length 1. They are provided two 8001-bp sequences with an true edit distance of 98. Output of the script should be piped into a new file, which gives time and function call stats sorted by total time to run.

Inside `minhash_combined.py` there are commented out `@profile` blocks. If you uncomment `from memory_profiler import profile` and these `@profile` sections, then you'll output the memory requirements for certain functions in the file.


Install requirements: pip3 install requirements.txt
Preprocessing running: python3 data_preprocessing.py data/roads/train/
